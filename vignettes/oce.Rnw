<<label=ctdrawplot,eval=FALSE>>=
data(ctdRaw)
plotScan(ctdRaw)
@
\begin{figure}
\begin{center}
\setkeys{Gin}{width=0.55\textwidth}
<<label=ctdrawfig, fig=TRUE,width=6, height=4, echo=FALSE>>=
<<ctdrawplot>>
@
\end{center}
\caption{Scanwise plot of the `{ctdRaw` sample data set.  Note the 
spike at the start, the equilibration phase before the downcast, and the
spurious freshening signal near the start of the upcast.}
\label{fig:ctdraw}
\end{figure}

\noindent This produces a two-panel plot (Figure~\ref{fig:ctdraw}) of the data
as a time-series, revealing not just the (useful) downcast, but also the
subsequent upcast sequence.  The x-axis in this plot is the scan number, which
is a convenient index for extraction of the downcast portion of the profile by
an essentially manual method, e.g. proceeding with a sequence of commands such
as
<<ctdscaneg,eval=false>>=
plotScan(ctdTrim(ctdRaw, "range",
                 parameters=list(item="scan", from=140, to=250)))
plotScan(ctdTrim(ctdRaw, "range",
                 parameters=list(item="scan", from=150, to=250)))
@
This is the ``gold standard'' method, which is recommended for detailed
work. However, for quick work, you may find that the automatic downcast
detection scheme works adequately, e.g.
<<ctdtrimeg,eval=false>>=
ctdTrimmed <- ctdTrim(ctdRaw)
@

It should be noted that @ctdTrim inserts entries into the object's log
file, so that you (or anyone else with whom you share the object) will be able to
see the details of how the trimming was done.


Once the profile has been trimmed, you may wish to use `{ctd.decimate()`
to smooth the data and interpolate the smoothed results to uniformly-spaced
pressure values. For example, a quick examination of a file might be done by the
following:
<<ctddectrim,eval=false>>=
plot(ctdDecimate(ctdTrim(read.ctd("stn123.cnv"))))
@

\subsection{Example with WOCE archive data}

The package has a harder time scanning the headers of data files in the WOCE
archive format than it does in the Seabird format illustrated in the previous
examples. This is mainly because front-line researchers tend to work in the
Seabird format, and partly because the WOCE format is odd. For example, the
first line of a WOCE file is of the form `{CTD,20060609WHPOSIODAM` (or
`{BOTTLE,...`).  Scanning the item to the left of the comma is not
difficult (although there are variants to the two shown, e.g. `{CTDO`
sometimes occurs).  The part to the right of the comma is more difficult.  The
first part is a date (yyyymmdd) so that's no problem.  But then things start to
get tricky.  In the example provided, this text contains the division of the
institute (WHPO), the institute itself (SIO), and initial of the investigator
(DAM). The problem is that no dividers separate these items, and that there seem
to be no standards for the item lengths. Rather than spend a great deal of time
coding special cases (e.g. scanning to see if the string `WHOI` occurs in
the header line), the approach taken with `oce` is to ignore such issues
relating to quirky headers.  This frees up time to work on more important
things, such as plotting the data.

It is possible to access object constituents directly, e.g.  `x@data$salinity`
is the salinity stored in a CTD object named `x`, but this is not the preferred
method of access.  The better scheme is to use the *accessor functions* that are
provided with all oce objects.  This relies on double-square-bracket notation,
e.g.  \verb+x[["salinity"]]+ yields salinity (from the \verb+data+ slot of the
object) and \verb+x[["station"]]+ yields the station identifier (from the
\verb+metadata+ slot).

But even though it's possible to manipulate object elements directly, it is
typically not a good idea.  The reason is that the object will be modified
without having an entry inserted into its processing log.  Thus, it is a bad
idea to write
<<ctdfix1,eval=false>>=
x <- read.ctd("nnsa_00934_00001_ct1.csv", type="WOCE")
x[["institute"]] <- "SIO" # better (using an accessor) but still bad
@
and a better idea to write
<<ctdfix2,eval=false>>=
x <- read.ctd("nnsa_00934_00001_ct1.csv", type="WOCE")
x <- oceEdit(x, "institute", "SIO") # better way
@
Even better, provide a reason for the change, and sign the change with your
name:
<<ctdfix3,eval=false>>=
x <- read.ctd("nnsa_00934_00001_ct1.csv", type="WOCE")
x <- oceEdit(x, "institute", "SIO", "human-parsed", "Dan Kelley")
@

For a real-world example (with warts!), visit
\url{http://cchdo.ucsd.edu/data_access?ExpoCode=58JH199410} and download the zip
file containing the Arctic section called ``CARINA'', measured in 1994. Expand
the zip file, enter the directory, and run the code below.
<<arcticeg,eval=false>>=
library(oce)
# Source: http://cchdo.ucsd.edu/data_access?ExpoCode=58JH199410
files <- system("ls *.csv", intern=TRUE)
for (i in 1:length(files)) {
    cat(files[i], "\n")
    x <- read.ctd(files[i])
    if (i == 1) {
        plotTS(x, xlim=c(31, 35.5), ylim=c(-1, 10), type="l", col="red")
    } else {
        lines(x[["salinity"]], x[["temperature"]], col="red")
    }
}
@

What you'll see is an overall $T$-$S$ diagram for the entire dataset. It may take
a while, since the dataset contains over 90,000 observations. You may note that,
even though this is an official, quality-controlled dataset, it is not without
problems. The graph that is produced by this code has several spurious lines
oriented horizontally (indicating spurious salinity) and vertically (indicating
spurious temperature). One way to find such values is to put the lines
<<rangeg,eval=false>>=
print(range(x[["temperature"]]))
print(range(x[["salinity"]]))
@
after the @read.ctd() command. One thing you'll find is that station 987
has a minimum salinity range of 0.0009 to 987. These values are clearly in
error, as are the temperatures at this spot in the file. (It is perhaps
revealing that the spurious salinity is equal to the station number.) Indeed, at
this spot in the file it can be seen that the pressure jumps from 1342 to 0, and
then starts increasing again; the file contains two profiles, or the same
profile twice. This is not the only flaw that is revealed by the graph, and by
@range commands; a generous user would spend a week tracking down such
issues, and would then contact the data provider (or the chief scientist of the
field work) with specific suggestions for correcting the files. The point here
is to highlight how this package can be used with real-world data.

\subsection{Section plots}
The commands
<<label=sectionplot,eval=FALSE>>=
data(section)
plot(section, which=c(1, 2, 3, 99))
@
will plot a summary diagram containing sections of
$T$, $S$, and $\sigma_\theta$, along with a chart indicating station
locations. In addition to such overview diagrams, @plot can also create
individual plots of individual properties.

\workedexercise{3}{Draw a $T$-$S$ diagram for the section data, colour-coded by station}


The Halifax section is supplied in a pre-gridded format, but some datasets have
different pressure levels at each station.  For such cases, the
@sectionGrid function may be used, e.g.
<<fig=FALSE, eval=TRUE, echo=FALSE>>=
jpeg("section.jpg", quality=75, width=600, height=700, pointsize=12)
@
<<>>=
data(section)
GS <- subset(section, 102<=stationId&stationId<=124)
GSg <- sectionGrid(GS, p=seq(0, 1600, 25))
plot(GSg, which=c(1,99), map.xlim=c(-85,-(64+13/60)))
@
<<fig=FALSE, eval=TRUE, echo=FALSE, results=hide>>=
dev.off()
@
produces Figure~\ref{fig:section}.  The ship doing the sampling was
travelling westward from the Mediterranean towards North America, taking 124
stations in total; the @indices value selects the last few
stations of the section, during which the ship heading was changed to run in a
northwesterly direction, to cross isobaths (and perhaps, the Gulf Stream) at
right angles.

\begin{figure}
\begin{center}
\setkeys{Gin}{width=1\textwidth}
\includegraphics[width=\hsize]{section}
\end{center}
\caption{\label{fig:section}
  Portion of the CTD section designated A03, showing the Gulf Sream region.  The
  square on the cruise track corresponds to zero distance on the sections.
}
\end{figure}

\workedexercise{4}{Plot dynamic height and geostrophic velocity across the Gulf Stream.}

\section{Maps}


% Coastline data are available from a variety of sources, e.g.
% @http://www.ngdc.noaa.gov/mgg_coastline/.  The function
% @read.coastline can handle reading that format (plus some other formats),
% and @plot on the resulting object will produce a simple coastline map.
% The only real advantage over plotting things yourself is that latitude and
% longitude are scaled to give natural shapes near the centre of the plot.
% 
% Bathymetric charts, or more generally topographic maps, can be produced easily,
% e.g. (Figure~\ref{fig:projection})

There are several ways to handle map projections in R and other systems. Oce
uses the @rgdal package to calculate the details of map projections.  A
suite of functions for plotting maps is provided.  The first step is to use
``@mapPlot()'' to construct the map, and after that, points can be added
with @mapPoints@, lines with \verb@mapLines, etc. For example,
<<eval=FALSE, echo=FALSE>>=
## NOTE: travisCI doesn't have rgdal included and I don't want to make
## oce *depend* on it, so I built up the png and included it in git.
png("projection.png", width=800*0.5, height=450*0.5, pointsize=13*0.5)
#pdf("projection.pdf", width=8, height=4.5, pointsize=13)
#par(mar=rep(0, 4))
@
<<eval=FALSE>>=
library(oce)
data(coastlineWorld)
par(mar=rep(0, 4))
mapPlot(coastlineWorld, projection="+proj=wintri", fill="lightgray")
@
plots a world coastline in the Winkel Tripel projection, using light gray ink
for the land (Figure~\ref{fig:projection}).
Adding the cruise track for the `oce` dataset called
@section is a simple matter
<<eval=FALSE>>=
data(section)
lon <- section[["longitude", "byStation"]]
lat <- section[["latitude", "byStation"]]
mapLines(lon, lat, col='red', lwd=2)
@

% <<fig=FALSE, eval=TRUE, echo=FALSE>>=
% jpeg("topo.jpg", quality=70, width=800, height=400, pointsize=13)
% @
% <<>>=
% library(oce)
% data(topoWorld)
% plot(topoWorld, clatitude=30, clongitude=370, span=9000)
% @
<<eval=FALSE, echo=FALSE, results=hide>>=
dev.off()
@
\begin{figure}
\begin{center}
\includegraphics[width=0.7\hsize]{projection}
\end{center}

\caption{World coastline in Winkel Tripel projection, with a cruise track
indicated in red.}
\label{fig:projection}
\end{figure}

\section{Sea-level data}

\subsection{Time-domain analysis}


The commands
<<fig=FALSE, eval=TRUE, echo=FALSE>>=
jpeg("sealevel.jpg", quality=70, width=800, height=600, pointsize=20)
@
<<>>=
library(oce)
#sealevel <- read.oce("../../tests/h275a96.dat")
data(sealevel)
plot(sealevel)
@
<<fig=FALSE, eval=TRUE, echo=FALSE, results=hide>>=
dev.off()
@
load and graph a build-in dataset of sea-level timeseries. The result, shown in
Figure~\ref{fig:sealevel}, is a four-panel plot. The top panel is a timeseries
view that provides an overview of the entire data set. The second panel is
narrowed to the most recent month, which should reveal spring-neap cycles if the
tide is mixed. The third panel is a spectrum, with a few tidal constituents
indicated. At the bottom is a cumulative spectrum, which makes these
narrow-banded constituents quite visible.

\begin{figure}
    \begin{center}
        \includegraphics[width=\hsize]{sealevel}
    \end{center}
    \caption{Sea-level timeseries measured in 2003 in Halifax Harbour.  (The
    spike in September is the storm surge associated with Hurricane Juan,
    regarded by the Canadian Hurricane Centre to be one of the most powerful and
    damaging hurricanes to ever hit Canada.)}
    \label{fig:sealevel}

\end{figure}

\workedexercise{5}{Illustrate Halifax sealevel variations during Hurricane Juan.}

\workedexercise{6}{Draw a spectrum of sea-level variation, with the M2 tidal component indicated.}

\subsection{Tidal analysis}

In a future version, tidal analysis will be provided, along the lines of the
t-tide package in Matlab.  A preliminary version of tidal analysis is provided
by the @tidem function provided in this version of the package, but
readers are cautioned that the results are certain to change in a future
version.  (The problems involve phase, and the inference of satellite nodes.)


\section{Temperature-Depth Recorder data}
The commands
<<fig=FALSE, eval=TRUE, echo=FALSE>>=
png("rsk.png", width=600, height=300, pointsize=13)
@
<<>>=
library(oce)
data(rsk)
plot(rsk, useSmoothScatter=TRUE)
@
<<fig=FALSE, eval=TRUE, echo=FALSE, results=hide>>=
dev.off()
@
produce a plot (Figure~\ref{fig:pt}) of temperature-depth logger
measurements made during St Lawrence Estuary Internal Wave Experiment, an
CFCAS/NSERC-funded research program in which the `oce` author was a principal
investigator.  The device was mounted on a mooring that tilted significantly
with the tide, yielding strong tidal signals in pressure as well as temperature,
thus providing a rough indication of the temperature profile.  Note that this
graph contains in-air as well as in-water data.
\begin{figure}
\begin{center}
\includegraphics[width=\hsize]{rsk}
\end{center}
\caption{Measurements made with a pressure-temperature recorder in the
  St Lawrence Estuary.  Note that the record contains in-air
  measurements made during an hour prior to lowering into the water,
  and during several days of transit from the field site back to
  Dalhousie University.  The text suggests a procedure for isolating
  in-water data, and removing the approximately 10 dbar atmospheric
  component of pressure.}
\label{fig:pt}
\end{figure}

\workedexercise{7}{Trim the in-air measurements from this `{rsk` record, and
then remove the atmospheric pressure from the signal.}


\section{Acoustic Doppler Current Profiler data}
The commands
<<fig=FALSE, eval=TRUE, echo=FALSE>>=
png("adp.png", width=800, height=250, pointsize=18)
@
<<label=adpplot>>=
library(oce)
data(adp)
plot(adp, which=1, adorn=expression({lines(x[["time"]], x[["pressure"]])}))
@
<<fig=FALSE, eval=TRUE, echo=FALSE, results=hide>>=
dev.off()
@
produce Figure~\ref{fig:adp}, showing currents made
in the St Lawrence Estuary Internal Wave Experiment.
\begin{figure}
\begin{center}
\setkeys{Gin}{width=\textwidth}
\includegraphics[width=\hsize]{adp}
\end{center}
\caption{Measurements made with an ADP in the
  St Lawrence Estuary.  The data were recorded in beam format, so a two-step
  process is used to convert to enu coordinates.  The black curve indicates
  the water surface, inferred from the pressure measured by the ADP.}
\label{fig:adp}
\end{figure}


\section{Working in non-English languages}

Many of the `oce` plotting functions produce axis labels that can be
displayed in languages other than English.  At the time of writing, French,
German, Spanish, and Mandarin are supported in at least a rudimentary way.
Setting the language can be done at the general system level, or within R; the
latter is illustrated below for French (which is coded @"fr" in the ISO
639 language standard).
<<>>=
library(oce)
Sys.setenv(LANGUAGE="fr")
data(ctd)
plot(ctd)
@

Most of the translated items were found by online dictionaries, and so they may
be incorrect for oceanographic usage.  Readers can help out in the translation
effort, if they have knowledge of how nautical words such as ``Pitch'' and
``Roll'' and technical terms such as ``Absolute Salinity'' and ``Potential
Temperature'' should be written in various languages.

\section{The future of oce}

The present version of `oce` can only handle data types that the author has
been using lately in his research. New data types will be added as the need
arises in that work, but the author would also be happy to add other data types
that are likely to prove useful to the Oceanographic community.  (The data types
need not be restricted to Physical Oceanography, but the author will need some
help in dealing with other types of data, given his research focus.) 

Two principles will guide the addition of data types and functions: (a) the
need, as perceived by the author or by other contributors and (b) the ease with
which the additions can be made.  One might call this development by triage, by
analogy to the scheme used in Emergency Rooms to focus medical effort.

% As for algorithms, there are plenty of gaps in `oce`.  Dealing
% with measurements of turbulence is a high priority for the author, for
% example, as is improving the functions for processing data from
% pressure-temperature sensors and acoustic Doppler current profilers.


\section{Development website}

The site \url{http://github.com/dankelley/oce} provides a window on the
development that goes on between the CRAN releases of the package. Please visit
the site to report bugs, to suggest new features, or just to see how `oce`
development is coming along.  Note that the `development` branch is used by
the author in his work, and is updated so frequently that it must be considered
unstable, at least in those spots being changed on a given day.  Every week or
so, as the `development` branch stabilizes, the changes are merged back
into the `master` branch.  Official CRAN releases derive from the
`master` branch, and are done when the code is considered to be of
reasonable stability and quality.  This is all in a common pattern for
open-source software.

%\begin{center}
%\vspace{2cm}
%
%------
%
%\vspace{2cm}
%
%See the end of the document for answers to exercises.
%
%\end{center}
%
%\newpage


%\vspace{2cm plus 2cm minus 2cm}
\clearpage
\section*{Answers to exercises}
\workedanswer{1}{Seawater properties}
<<>>=
library(oce)
swRho(34, 10, 100)
swTheta(34, 10, 100)
swRho(34, swTheta(34, 10, 100), 0)
swRho(34, swTheta(34, 10, 100, 200), 200)
plotTS(as.ctd(c(30,40),c(-2,20),rep(0,2)), grid=TRUE, col="white")
@

\workedanswer{2}{Profile plots}
Although one may argue as to the limits of the pycnocline, for illustration let us say it is in 5bar to 12dbar range.  One way to do this is
<<>>=
library(oce)
data(ctd)
pycnocline <- ctdTrim(ctd, "range",
                      parameters=list(item="pressure", from=5, to=12))
plotProfile(pycnocline, which="density+N2")
@
and another is
<<>>=
library(oce)
data(ctd)
pycnocline <- subset(ctd, 5<=pressure & pressure<=12)
plotProfile(pycnocline, which="density+N2")
@

\workedanswer{3}{TS diagram for section data}
The simplest way is to use accessor functions to extract salinity, etc.
<<>>=
library(oce)
data(section)
ctd <- as.ctd(section[["salinity"]], section[["temperature"]], section[["pressure"]])
plotTS(ctd)
@
but the point of \emph{this} exercise is to do the extraction manually, so a
more appropriate solution is as follows
<<>>=
library(oce)
data(section)
SS <- TT <- pp <- id <- NULL
n <- length(section@data$station)
for (stn in section@data$station) {
    SS <- c(SS, stn[["salinity"]])
    TT <- c(TT, stn[["temperature"]])
    pp <- c(pp, stn[["pressure"]])
}
ctd <- as.ctd(SS, TT, pp)
plotTS(ctd)
@


\workedanswer{4}{Gulf Stream}
(Try `?swDynamicHeight` for hints on smoothing.)
<<>>=
library(oce)
GS <- subset(section, 102<=stationId&stationId<=124)
dh <- swDynamicHeight(GS)
par(mfrow=c(2,1))
plot(dh$distance, dh$height, type="b", xlab="", ylab="Dyn. Height [m]")
grid()
# 1e3 metres per kilometre
f <- coriolis(GS@data$station[[1]]@metadata$latitude)
g <- gravity(GS@data$station[[1]]@metadata$latitude)
v <- diff(dh$height)/diff(dh$distance) * g / f / 1e3
plot(dh$distance[-1], v, type="l", col="blue", xlab="Distance [km]", ylab="Velocity [m/s]")
grid()
abline(h=0)
@
\workedanswer{5}{Halifax sealevel during Hurricane Juan.}
A web search will tell you that Hurricane Juan hit about midnight, 2003-sep-28.
The author can verify that the strongest winds occurred a bit after midnight -- that was the time
he moved to a room without windows, in fear of flying glass.
<<>>=
library(oce)
data(sealevel)
# Focus on 2003-Sep-28 to 29th, the time when Hurricane Juan caused flooding
plot(sealevel,which=1,xlim=as.POSIXct(c("2003-09-24","2003-10-05"), tz="UTC"))
abline(v=as.POSIXct("2003-09-29 04:00:00", tz="UTC"), col="red")
mtext("Hurricane\nJuan", at=as.POSIXct("2003-09-29 04:00:00", tz="UTC"), col="red")
@

\workedanswer{6}{Sealevel spectrum}

The first step is to load the data.
<<>>=
library(oce)
data(sealevel)
@
Next, we extract the elevation data
<<>>=
elevation <- sealevel[["elevation"]]
@
and then we return to standard R processing, to compute the spectrum, and 
indicate the M2 tide.
<<>>=
spectrum(elevation, spans=c(3,7))
abline(v=1/12.42)
mtext("M2",at=1/12.42,side=3)
@

\workedanswer{7}{Pressure-temperature Recorder plot}

The accuracy of automatic removal of the atmospheric component done
with `rsk.trim()` can be quite good if the instrument has recorded
in the air at the start and end of the record.  Even so, it always
makes sense to investigate the data by eye, in order to select a time
window.  Manual selection of a time window is also important when a
researcher is dealing with a set of instruments whose measuremnts are
to be combined and so need a uniform time base (e.g. to make a matrix
to be contoured).

The best plan is simply to plot the data interactively, and then to
narrow in on start and end times by plotting trial values, e.g.
<<>>=
abline(v=as.POSIXct("2008-06-25 00:00:00"),col="red")
@
with arrow keys being used to repeat commands that get edited as the
key times are located.

